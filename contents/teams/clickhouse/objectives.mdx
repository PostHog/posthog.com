**Data Team's Mission at PostHog**

Data Team's mission is to provide a storage and query engine that meets these requirements:
- Continue to meet the needs of the product today now and in the future
- Maintain and optimize our current ClickHouse deployment
- Elastically scale our capacity with little effort
- Support multiple query quality of service (QOS) guarantees (Real-time, Batch, etc.)
- Data is stored once and queryable from the appropriate tool
- Queries are optimized for cost and performance
- Tunable execution performance to allow trade-offs between cost and performance
- Storage is durable

In service of this mission, our goals are:

**Goals for Q3 2025:**

## Clickhouse Tooling

- **Migration (P1)**

- **Chargeback (P0)** - _Paweł Szczur_
    - Enable our customers to self service performance issues
    - Surface resource consumption
    - Usecase: Query analysis to avoid querying big ranges

- **SlopCop (query scheduling) (P0)** - _Ted Kaemming, Paweł Szczur_
    - Rate limiting
    - Queuing
    - Debouncing

- **Inserter (P1)** - _James Greenhill_

- **Mutator (P0)** - _Daniel Escribano, Ted Kaemming_
    - Dagster + table + interface
    - Mutation monitoring
    - Ensure Deletes Run

## Clickhouse Ops

- **Make ClickHouse ops easy** - _Daniel Escribano, James Greenhill_
    - Complete cluster management through IaC
    - EU coordinators
    - Bringing up and down nodes should require no thought
    - Runbook - more ideally automation
    - Tooling? Sneak attack pulumi
    - Much faster critical procedures (rely on ZK configuration more)
    - ClickHouseKeeping through Dagster
        - Part moving
        - Detached/unneeded parts cleaning
        - Resizing parts?
    - Disk management
        - Automatic disk provisioning based on thresholds (and limits)
    - Events TTL and actual data tiering
        - Some tables in Iceberg (Antalya)
        - Query_log
        - Query_metrics_log
        - Plan for events migration to Iceberg
