---
title: What launching Experimentation taught us about running effective A/B tests
---

1. Some kinds of experiments need less data
2. Choose the metric you want to track carefully
3. Bringing data to conversations, but also talking through causes.
4. Don't blindly trust data
5. Control groups? -> All experiments are relative.
  6. Selection bias
7. What if new information invalidates all old information?
8. Clinical trials are very different from website changes
9. Peeking Problem isn't really a _problem_ for decent products. If anything, peeking is addictive :P
10. Why not run every experiment on this global metric? That way, you're testing if overall product gets better or not. Simple yes and no, takes into account all factors.
