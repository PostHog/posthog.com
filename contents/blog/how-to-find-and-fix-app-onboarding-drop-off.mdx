---
title: How to fix your app onboarding drop-off points
date: 2025-12-29
rootPage: /blog
sidebar: Blog
showTitle: true
hideAnchor: true
author:
    - natalia-amorim
featuredImage: >-
    https://res.cloudinary.com/dmukukwp6/image/upload/Untitled_design_af9b8ab475.png
featuredImageType: full
category: General
tags:
    - Growth
    - Product engineers
seo:
    metaTitle: 'Product onboarding: How to fix drop-off points'
    metaDescription: 'A step-by-step recipe for finding where users drop off during app onboarding, understanding why it happens, and improving activation rates.'
---

import { CalloutBox } from 'components/Docs/CalloutBox'
import { Checkbox } from 'components/RadixUI/Checkbox'

*A PostHog recipe for people whose users keep leaving the table.*

| | |
|---|---|
| **Prep time** | ~30 minutes setup, ~1 week of data |
| **Difficulty** | Beginner-friendly |
| **Yields** | One less broken onboarding flow |
| **Best for** | Product engineers, technical founders, growth teams |
| **Outcome** | Better onboarding conversion boosts all downstream metrics from activation to retention to revenue.|

<p>
<CallToAction to="#step-1-prep-the-finish-line">
  Jump to recipe
</CallToAction>
</p>

---

Seeing your onboarding stats drop or stall can be discouraging, but **here's the good news:** [it doesn't mean your product sucks](/founders/product-market-fit-game) (phew!)

Onboarding drop-offs are usually an indication of friction, not rejection. Users don't rage-quit because they hate your product, they quit because something didn't make sense, didn't work, or asked for too much too soon.

It's like attempting a beef wellington, realizing you're in over your head somewhere around the "wrap the beef in mushroom duxelles" step, and bailing to order pizza instead. *Ask me how I know.*

**Even better news**: onboarding friction is measurable, debuggable, and fixable. 

![App onboarding drop off recipe card](https://res.cloudinary.com/dmukukwp6/image/upload/recipe_card_296e169291.png)

## What you'll need

### Ingredients

You don't need a massive stack for this recipe.

**Required:**
<div className="space-y-4 pl-6">
  <div className="flex items-center gap-2"><Checkbox id="req-1" defaultChecked={false} /><label htmlFor="req-1" className="text-sm cursor-pointer"><a href="/blog/best-open-source-analytics-tools">A product analytics tool</a> (for building your onboarding funnel)</label></div>
  <div className="flex items-center gap-2"><Checkbox id="req-2" defaultChecked={false} /><label htmlFor="req-2" className="text-sm cursor-pointer"><a href="/blog/best-session-replay-tools">A session replay tool</a> (for watching what users actually do)</label></div>
</div>

*Optional, but recommended:*
<div className="space-y-4 pl-6">
  <div className="flex items-center gap-2"><Checkbox id="opt-1" defaultChecked={false} /><label htmlFor="opt-1" className="text-sm cursor-pointer"><a href="/docs/product-analytics/autocapture">Autocapture</a> (for skipping manual event setup)</label></div>
  <div className="flex items-center gap-2"><Checkbox id="opt-2" defaultChecked={false} /><label htmlFor="opt-2" className="text-sm cursor-pointer"><a href="/docs/data/cohorts">Cohorts or segmentation</a> (for slicing data by user type)</label></div>
  <div className="flex items-center gap-2"><Checkbox id="opt-3" defaultChecked={false} /><label htmlFor="opt-3" className="text-sm cursor-pointer"><a href="/feature-flags">Feature flags</a> (for safely rolling out fixes)</label></div>
  <div className="flex items-center gap-2"><Checkbox id="opt-4" defaultChecked={false} /><label htmlFor="opt-4" className="text-sm cursor-pointer"><a href="/experiments">Experiments</a> (for measuring your changes)</label></div>
  <div className="flex items-center gap-2"><Checkbox id="opt-5" defaultChecked={false} /><label htmlFor="opt-5" className="text-sm cursor-pointer"><a href="/surveys">Surveys</a> (for getting direct feedback from users)</label></div>
</div>

 <br />

<details>
<summary><strong>Substitutions</strong></summary>

**No session replay tool?** You can interview users directly instead, but you'll be relying on their memory of what happened rather than what actually happened. It works, it's just slower and less reliable. [Here's our guide to running effective user interviews](/blog/10x-engineers-do-user-interviews) if you go this route.

**No surveys?** It's okay, replays will get you 80% of the way there; the other 20% is context you'll have to infer.

**No feature flags?** You can ship straight to production. We won't judge. (...we will judge a little.) If something breaks, you'll just have to roll back manually. [Here's why we think feature flags are worth it](/product-engineers/feature-flag-benefits-use-cases).

**No cohorts or segmentation?** You can still run this recipe, you'll just be looking at all users as one group. If your drop-off is consistent across everyone, that's fine. If it's not, you'll have a harder time figuring out who's actually struggling.
</details>

You'll also need:
- **A clear definition of what "successful onboarding" looks like**. This is [your activation event](/newsletter/wtf-is-activation) ‚Äì the moment a user has gotten enough value to stick around (more on this below).
- **[Events firing](/tutorials/event-tracking-guide) & at least a few hundred users going through your flow**. You need enough data to spot patterns. If you're at an earlier stage, you can still follow this recipe; just watch more replays and lean harder on qualitative signals until your numbers catch up.

### **Want to cook with PostHog? Great choice.**

If you haven't set it up yet, [start here](/docs/getting-started/install). Make sure you're capturing the key events in your onboarding flow (signups, form completions, button clicks, etc.). If you have autocapture enabled, you're probably already covered.

We highly recommend calling [`posthog.identify()`](/docs/product-analytics/identify) when users sign up or log in; you'll be able to track them across sessions and devices, which makes your funnel data much more reliable.

<p>
<CallToAction to="https://app.posthog.com/signup">
  Cook with PostHog ‚Äì it's free!
</CallToAction>
</p>

## Step 1: Prep the finish line

Before you can fix your onboarding, you need to [define what a successful onboarding flow actually means](/docs/new-to-posthog/activation). This is your activation event, the foundation of your activation metrics and the thing you'll measure everything against.

Ask yourself: What's the moment when a user has gotten enough value that they're likely to stick around? What you're looking for is a **value-producing action**.

Some examples:
- **For an e-commerce app**: Added item to cart and completed checkout
- **For a streaming service**: Watched their first video or listened to their first song
- **For a project management tool**: Created their first project and invited a teammate
- **For a fintech app**: Linked their bank account or made their first transaction
- **For a social app**: Followed their first account or posted their first content
- **For an analytics product**: Sent their first event and created an insight
- **For a CRM**: Added their first contact and sent an email

Not sure what yours is? Try looking at your retention data ‚Äì [what do retained users do that churned users don't?](/product-engineers/customer-retention-metrics) That should give you a starting point. 

Here's [how we figured out our activation metric at PostHog](/product-engineers/activation-metrics) (spoiler: it took a few iterations).

Pick one. Be opinionated. You can always adjust later.

<details>
<summary><strong>üë®‚Äçüç≥ Chef's tip</strong></summary>
Don't confuse the appetizer for the main course; signing up or landing on a dashboard aren't meaningful enough steps to be considered product activations, for example. Also, your activation event might change over time ‚Äì what predicted retention two years ago might not be the best signal today, so revisit it if needed.
</details>

<CalloutBox icon="IconInfo" title="You're ready for the next step when...." type="fyi">

You can complete the sentence: "A user has successfully onboarded when they ____."

</CalloutBox>

## Step 2: Build a funnel

Now you're ready to cook.

In your analytics tool, create a funnel with the steps a user must complete to reach your activation event.

A simple example:
1. `$pageview` on `/signup/success` (or a custom `signed_up` event)
2. `profile_completed`
3. `first_project_created`
4. `teammate_invited` (the last step is your activation event)

A few tips:
- Start with 3-5 steps max. Too many steps and you'll have trouble identifying the real problem areas.
- Use sequential order (the default) so users must complete steps in the order you've defined.
- Set a reasonable conversion window (7 to 14 days is a good starting point).

**If using PostHog:**

Head to [Product Analytics](https://app.posthog.com/insights) ‚Üí **New insight** ‚Üí [**Funnel**](/docs/product-analytics/funnels). If you have [autocapture](/docs/product-analytics/autocapture) enabled, many of these events may already be tracked for you; check your [activity](https://app.posthog.com/events) to see what's coming in.

<details>
<summary><strong>üë®‚Äçüç≥ Chef's tip</strong></summary>
Start with your core flow. Once it's optimized, create separate funnels for specific segments. Don't forget to name your funnel something specific (e.g., "Self-serve onboarding Q1 2025") so future-you knows what it's measuring when you have 47 funnels.
</details>


<CalloutBox icon="IconInfo" title="You're ready for the next step when...." type="fyi">

Your funnel is prepped, ending with your activation event, saved, and ready to collect data.

</CalloutBox>

## Step 3: Let it simmer

Save your funnel and let data collect for at least a week. You need enough users going through the flow to see meaningful patterns; looking too early is how you end up "fixing" problems that don't exist.

As a rough guideline:
- A few hundred users entering onboarding is usually enough to start
- More is better if you plan to [segment by user type or device later](/blog/how-to-do-user-segmentation)

While you wait, you can:
- [Set up session replay, if you haven't already](/docs/session-replay)
- [Prep an exit survey for later](/docs/surveys/creating-surveys) (we'll use it in Step 6)

<details>
<summary><strong>üë®‚Äçüç≥ Chef's tip</strong></summary>
Resist the urge to peek daily. Set a calendar reminder for one week out ‚Äì watching the pot won't make it boil faster.
</details>

<CalloutBox icon="IconInfo" title="You're ready for the next step when..." type="fyi">

Your data has had time to marinate ‚Äì at least a few hundred users through the funnel with clear conversion rates at each step. Undercooked data leads to undercooked fixes.

</CalloutBox>

## Step 4: Find the leak

Now that your funnel is showing you where users are falling off, look for:
- **The step with the lowest relative conversion rate** ‚Äì this is usually your biggest opportunity
- **Absolute numbers** ‚Äì sometimes a step has decent conversion but is still losing you thousands of users

If everyone drops off at the same step, it's probably a UX problem. Something about that step is broken or confusing for all users.

If only *some* users drop off, it's a context problem. Something about who they are or how they got there is causing friction.

If it's a context problem, try segmenting your funnel to find a clearer diagnosis:
- New users vs. returning users
- Invited users vs. self-serve signups
- Browser, device, or OS
- Plan type or pricing tier

**If using PostHog:**

Click on the drop-off number in your funnel to see the actual users who didn't make it. Use [breakdowns](/docs/product-analytics/funnels#breakdowns) to slice your funnel by user properties, device, or any event property. If you have many steps or breakdown values, you can also sort for poor performers in terms of number of conversions, conversion percentage, and even time in the **Detailed results** section.

<details>
<summary><strong>üë®‚Äçüç≥ Chef's tip</strong></summary>
You can export your cohort of dropped-off users and use it to target them with win-back marketing campaigns or surveys later.
</details>

<CalloutBox icon="IconInfo" title="You're ready for the next step when..." type="fyi">

You're able to say: "Users drop off most at *[this step]*" and "It affects *[these users]* more than others." If you can't say both, don't move on yet.

</CalloutBox>

## Step 5: Watch the replays

You know where users drop off, [now you need to find out *why*](/tutorials/explore-insights-session-recordings).

Watch 10‚Äì15 recordings. You're looking for patterns:
- Are users getting confused at a specific UI element?
- Are they rage-clicking something that doesn't work?
- Are they abandoning after seeing a specific screen (pricing, permissions request, etc.)?
- Are they hitting errors? (Check the console logs in the replay; PostHog [captures these](/docs/session-replay/console-log-recording) too.)
- Is something failing quietly? Look at network requests if you have [network recording](/docs/session-replay/network-recording) enabled.

If recordings are looking wildly different from one user to the next, go back to Step 4 and segment further; you're probably mixing multiple problems together. 

**If using PostHog:**

- Fastest way: Click directly on the drop-off in your funnel ‚Äì PostHog will pull up recordings for those users automatically. (This is one of the nice things about having replay and analytics in one tool!)

- Manual way: In [Session Replay](https://app.posthog.com/replay), click **Show filters** ‚Üí **Filter for events or actions** ‚Üí select the last event users completed before dropping off. See our [session replay filtering guide](/tutorials/filter-session-recordings) for more.

If you saved a cohort in Step 4, you can filter replays by that cohort directly.

<details>
<summary><strong>üë®‚Äçüç≥ Chef's tip</strong></summary>
Don't just watch drop-offs. Sometimes successful users struggled through the same friction ‚Äì they just pushed through anyway. Watch both to taste the difference.
</details>

<CalloutBox icon="IconInfo" title="You're ready for the next step when..." type="fyi">

You're able to say "Users drop off here because *[this thing]* keeps happening."

</CalloutBox>

## Step 6: Fold in survey data *(optional, but recommended)*

This step isn't required, but it can be the difference between a good fix and the right fix.

### Exit survey (for users who drop off)

Trigger this when users are about to abandon your onboarding flow:
- **Question:** "What's stopping you from finishing setup?" (open text)
- **Display conditions:** Show on your onboarding URL + after 30‚Äì60 seconds of inactivity, or on exit intent

You likely won't get a ton of responses, but the ones you do get can be really useful signals.

### Completion survey (for users who made it)

Survey users who did complete onboarding to understand what almost stopped them:
- "What was the hardest part of getting started?"
- "What, if anything, almost made you give up?"

Trigger this right after your activation event fires; they'll remember while it's fresh.

**If using PostHog:**

Go to [Surveys](https://app.posthog.com/surveys) ‚Üí [**New survey**](/docs/surveys/creating-surveys).

You can set display conditions based on URL, user properties, or events. For the completion survey, trigger it when your activation event fires.

<details>
<summary><strong>üë®‚Äçüç≥ Chef's tip</strong></summary>
Keep surveys short. One or two open-ended questions max. Users will give you more when you ask for less. Also, remember survey responses are seasoning, not the main dish; it's okay to just have a handful of responses. A few strong signals beat hundreds of vague ones.
</details>

<CalloutBox icon="IconInfo" title="You're ready for the next step when..." type="fyi">

You've seasoned your data with user feedback that confirms, refines, or challenges what you saw in replays.

</CalloutBox>

## Step 7: Form a hypothesis and ship a fix

By now you should have:
- Quantitative data on where users drop off (funnel)
- Behavioral data on what they were doing (replays)
- Direct feedback on what they were thinking (surveys)

Mix these into a hypothesis: "[These] Users are dropping off at [step] because [reason]."

Some common fixes:
- **Simplify your flow** ‚Äì reduce fields, remove friction, break it into smaller steps, make a required field optional
- **Add guidance** ‚Äì tooltips, progress indicators, inline help
- **Squash any bugs** ‚Äì if replays showed errors, fix them
- **Reorder the flow** ‚Äì maybe you're asking for too much too soon

<details>
<summary><strong>üë®‚Äçüç≥ Chef's tip</strong></summary>
One ingredient at a time. If you change five things at once, you won't know what fixed it (or broke it). Also, write down your hypothesis before you ship. It's easy to retrofit a narrative after you see results ‚Äì having it on record keeps you honest.
</details>

<CalloutBox icon="IconInfo" title="You're ready for the next step when..." type="fyi">

You've got one fix in the oven, designed to address your hypothesis.

</CalloutBox>

## Step 8: Taste before serving *(optional, but recommended)*

Whatever the change, don't dump it straight into production, roll it out gradually if you can [**using feature flags**](/blog/best-open-source-feature-flag-tools).

Feature flags let you:
- Release to 10‚Äì20% of users first, then ramp up
- Target specific user segments (e.g., new users only)
- Kill the change instantly if something goes wrong

Want statistical proof it worked? [Run an A/B experiment](/product-engineers/how-to-do-ab-testing). This is optional, [not every fix needs one](/product-engineers/ab-testing-mistakes). But it's worth it when:
- The change is significant (like a full flow redesign)
- You're debating between multiple solutions
- You need to convince stakeholders with data

While step isn't mandatory, [it helps avoid "we think this worked" decisions](/newsletter/what-we've-learned-about-ab-testing).

**If using PostHog:**

Use [feature flags](/docs/feature-flags) to roll out your fix to a percentage of users first.

To run an experiment, go to [Experiments](https://app.posthog.com/experiments) ‚Üí [**New experiment**](/docs/experiments/creating-an-experiment). Use your feature flag as the basis ‚Äì PostHog will split users into control and test groups and track your funnel as the goal metric.

<details>
<summary><strong>üë®‚Äçüç≥ Chef's tip</strong></summary>
If you're nervous about a big change, start at 5% rollout. You can always ramp up, but you can't un-serve a burnt dish. Also, not every fix needs a full experiment ‚Äì but if it's a big change, or you need to convince stakeholders, statistical proof is worth the extra time.
</details>

<CalloutBox icon="IconInfo" title="You're ready for the next step when..." type="fyi">

Your fix is out of the kitchen, live (ideally behind a feature flag) and collecting data.

</CalloutBox>

## Step 9: Measure the improvement

After your fix has been live for a bit:
- Go back to your funnel
- Compare conversion rates before and after your change (most analytics tools let you view trends over time)
- Watch a few new replays to confirm the friction is gone

Things to check:
- Did funnel completion improve?
- Did drop-off move to a different step?
- Do replays show smoother behavior?

**If using PostHog:**

Set your funnel's **Graph type** to **Historical trends** to see conversion over time.

If you used a feature flag or experiment, check the results in [Experiments](https://app.posthog.com/experiments) to see the impact with statistical significance. For another perspective on your funnel, you can also break it by whether that feature flag was enabled for that user.

<details>
<summary><strong>üë®‚Äçüç≥ Chef's tip</strong></summary>
Screenshot your before/after funnels. They make great artifacts for retros, stakeholder updates, and convincing your team that this stuff actually works.
</details>

<CalloutBox icon="IconInfo" title="You're done when..." type="fyi">

You can see a lift in activation rates after deploying your fix.

If it didn't work as expected, that's okay. Go back to Step 4 with a new hypothesis. Onboarding optimization is iterative, you're rarely done after one fix.

</CalloutBox>

## Why this recipe works especially well with PostHog

Most teams piece this workflow together across 3‚Äì4 different tools: analytics in one place, replays in another, surveys or feature flags somewhere else. It works, but it's slow and you lose context switching between tabs.

With PostHog, [everything's connected in one place](/products):
- **Funnels** show you where users drop off
- **Breakdowns** show you who's struggling
- **Session replay** shows you why
- **Surveys** tell you what users were thinking
- **Feature flags** let you ship fixes safely
- **Experiments** confirm whether the fix actually worked

[Get started free](https://app.posthog.com/signup) with 1M events, 5K recordings, and 1M feature flag requests free every month!

<ArrayCTA />

### FAQ

<details>
<summary><strong>What is product activation?</strong></summary>

Product activation is the moment a user experiences enough value to stick around. It's the bridge between signing up and becoming an engaged user, and it's one of the most important metrics for product-led growth.

The key product activation metrics to keep an eye out for are **activation rate** (% of signups who activate), **time to activate** (how long it takes), and **onboarding completion rate** (% who finish your onboarding flow). Track all three to get the full picture.
</details>

<details>
<summary><strong>What's the difference between app onboarding and product activation?</strong></summary>

**Onboarding is the flow** ‚Äî the steps you guide users through. **Activation is the outcome** ‚Äî the moment they get value. Good onboarding leads to activation, but they're not the same thing.
</details>

<details>
<summary><strong>What is onboarding drop-off?</strong></summary>

**Onboarding drop-off** is when users start your onboarding flow but leave before completing it. They signed up and showed intent, but never reached the point where they experienced real value from your product (your activation event).

Onboarding drop-off is [not the same as churn](/tutorials/churn-rate) ‚Äì these users never really started using your product in the first place.
</details>

<details>
<summary><strong>What‚Äôs the difference between onboarding drop-off and churn?</strong></summary>

**Onboarding drop-off** happens before users get value. They never activate.

**Churn** happens after activation. Users got value, used the product for some time, and then stopped.

Drop-off is usually caused by UX friction or broken flows. Churn is more often driven by value, habit, pricing, or competition.
</details>

<details>
<summary><strong>What causes users to drop off during onboarding?</strong></summary>

The most common causes are:
- Asking for too much information too soon  
- Confusing or unclear UI  
- Unclear next steps or lack of guidance  
- Broken flows, errors, or silent failures  
- Required steps that don‚Äôt feel required  
- Onboarding that takes too long to complete  

</details>

<details>
<summary><strong>What‚Äôs a good onboarding completion rate?</strong></summary>

There‚Äôs no universal benchmark.

For self-serve SaaS, **20‚Äì40%** onboarding completion is common. Higher-touch products with sales involvement often see higher rates.

More important than benchmarks is tracking your own completion rate over time and improving it incrementally.
</details>

<details>
<summary><strong>What‚Äôs the biggest mistake teams make with onboarding analytics?</strong></summary>

Optimizing the wrong metric.

Teams often track signups, pageviews, or dashboard loads instead of the action that actually predicts retention. **If your activation event is wrong, everything downstream will be misleading.**
</details>

<details>
<summary><strong>How do I reduce onboarding drop-off?</strong></summary>

Start by diagnosing the problem.

Identify where users drop off, then look at what actually happens at that step. Fix **one thing at a time** by simplifying the flow, adding guidance, removing unnecessary fields, fixing bugs, or reordering steps.

Roll out changes gradually so you can measure impact and roll back if needed.
</details>

<details>
<summary><strong>What tools do I need to track and fix onboarding drop-offs?</strong></summary>

At a minimum, you need:
- [**Product analytics**](/blog/best-open-source-analytics-tools) to build funnels and see where users drop off  
- [**Session replay**](/blog/best-session-replay-tools) to understand what users were doing before they left  

You can assemble this with separate tools (for example, analytics, replay, feature flags, and experiments), but that usually means more setup, more context switching, and slower iteration.

Or you can use a unified platform like PostHog to do all of this in one place.
</details>

<details>
<summary><strong>Can I do this without a unified analytics tool?</strong></summary>

Yes, but it‚Äôs harder.

Most teams end up stitching together funnels, replays, surveys, and experiments across multiple tools, which slows analysis and makes it harder to connect cause and effect.

A unified stack makes it much easier to move from ‚Äúwhere users drop off‚Äù to ‚Äúwhy‚Äù to ‚Äúdid this fix work?‚Äù
</details>

### Pairs well with

- [The AARRR pirate funnel explained](/product-engineers/aarrr-pirate-funnel)
- [10 things we've learned about A/B testing](/newsletter/what-we've-learned-about-ab-testings)
- [How to think like a growth engineer](/newsletter/think-like-a-growth-engineer)
- [What we've learned about talking to users](/blog/product-for-engineers-1)
- [50 things we've learned about building successful products](/newsletter/50-product-learnings)

...hungry for more?

<NewsletterForm />

### Did you make this recipe?

Share your before-and-after funnel below.

‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê "*Finally fixed our onboarding. Down to only 3 existential crises per quarter.*" ‚Äì Actual user, probably