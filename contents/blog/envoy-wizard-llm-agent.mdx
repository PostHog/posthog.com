---
title: "We built an AI envoy, you can too"
date: 2025-05-06
author:
  - danilo-campos
featuredImage: >-
  https://res.cloudinary.com/dmukukwp6/image/upload/steal_this_code_90451c15ca.png
featuredImageType: full
tags:
    - Engineering
    - LLM
---

import Prompt from '../docs/integrate/_snippets/agent-prompt.mdx'

AI agents are taking over the workflows of software development. They can burn through boilerplate and tedium fast, getting working prototypes up in minutes.

But LLM codegen has two annoying problems...

The first? **There are so many stupid ways to build software**.

When an agent sets out to write code, it has many viable paths to both solve the problem and introduce mistakes. Mistakes are especially common for newer, upstart projects.

Scale is one way to compensate: fill the training set with enough statistical weight favoring the correct implementations and you’re less likely to see the boneheaded stuff.

But that’s a lot of effort, plus significant lag time as you await scraping and training. You want correct agent behavior *today*.

The second problem? **LLMs are so expensive**.

Training models is expensive, GPUs are expensive. Sometimes it feels like the best case scenario is a successful donation machine piped to Anthropic's coffers.

But: good news. You can join this revolution in a way that won't drain your bank account.

Build an **envoy**: perfectly conventional software *you control* that developers can inject into their agent sessions with just a prompt.

## What's an envoy?

To coin a term, an **envoy** is code that meets an AI agent on your behalf.

See, **these agents can run terminal commands**, so any CLI-based program can adopt this pattern. Envoys provide a side entrance into any agent session. A CLI app can print things to the terminal, adding to the context the agent has available. This is in addition, of course, to all the modifications such a tool can make to the project's code and configuration itself.

With this deterministic surface introduced to the agent workflow, you can reliably and predictably:

- Enforce progression conditions, not moving to another step until requirements are satisfied  
- Enforce correct versioning
- Use API interactions to populate secrets and other details, while enforcing good version control hygiene to prevent checking in those secrets
- Introduce specific fragments of code verbatim
- Inject up-to-date documentation and agent rules into the project to course-correct future agent sessions  
- Configure [MCPs](/docs/model-context-protocol) and other project-specific settings
- Deliver LLM-based transformations on code, using prompts, context and model versions that you carefully select and design for reliable outcomes
- Enjoy same-day updates to agent workflows, just like the rest of your software
- Provide up-to-date information to the agent specific to a user's project or account

Think of it like a sheepdog that keeps the agent session within a territory that is productive rather than stupid, adhering to best practices **you** as a developer can describe in code.

Naturally, we're building our own envoy already. It's a beta, but it's already very helpful and the feedback is encouraging.

## Example code: the PostHog wizard

The PostHog [wizard](https://github.com/PostHog/wizard) started its life as an interactive command line tool for automating the basics of a PostHog integration. It grabs an API key from a user’s account and uses it to populate a `.env` file.

From here it uses LLMs and consistent prompting to read through the user’s code and integrate PostHog correctly.

It turns out this is handy behavior: other LLM workflows were *hallucinating* PostHog API keys and agents were using out-of-date code to perform integrations.

To make the wizard into an effective **envoy**, all we had to do was add an argument that suppressed the interactivity, following the default path all the way through the workflow. The agent just runs the command in its terminal, on the user's behalf.

![Agent session](https://res.cloudinary.com/dmukukwp6/image/upload/agent_session_04407be548.gif)

Now anyone using an AI agent can copy and paste one prompt and get a working integration in about 90 seconds. It’s the best of all worlds:

- No hallucinations of API keys  
- No out of date patterns  
- Smooth, automated code generation

We can ship as many updates to the wizard as fast as we like, and the improved behavior will be available to developers who use agents instantly, with no other configuration.

Try it yourself. Paste this into the agent chat for Cursor, Bolt, and others:

<Prompt />

We’ve got support for Next.js, React, Svelte, and React Native, with others coming soon.

## Steal this code

[Joshua](https://posthog.com/community/profiles/32497) has been working hard to increase the surface of the wizard and make it more reliable. [There's loads to learn from it](/newsletter/building-ai-features).

The project also demonstrates how you can implement PostHog in your own CLI products, gathering all sorts of useful data. We know how many runs are successful, and how many are cancelled, and this information is reported alongside the rest of our PostHog data. You can do this too!

[Fork the wizard](https://github.com/PostHog/wizard) – it's MIT licensed – and you can use it as your own starting place for an envoy.

You really *don't* have to spend a lot of money to get into the coding agent mix.