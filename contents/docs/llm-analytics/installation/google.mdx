---
title: Google LLM analytics installation
showStepsToc: true
---

import LLMsSDKsCallout from './_snippets/llms-sdks-callout.mdx'
import VerifyLLMEventsStep from './_snippets/verify-llm-events-step.mdx'

LLM analytics is currently considered in `beta`. To access it, enable the [feature preview](https://app.posthog.com/settings/user-feature-previews#llm-observability) in your PostHog account.

<Steps>

<Step title="Install the PostHog SDK" badge="required">

Setting up analytics starts with installing the PostHog SDK for your language. LLM analytics works best with our Python and Node SDKs.

<MultiLanguage>

```bash
pip install posthog
```

```bash
npm install @posthog/ai posthog-node
```

</MultiLanguage>

</Step>


<Step title="Install the Google Gen AI SDK" badge="required">

Install the Google Gen AI SDK:

<MultiLanguage>

```bash
pip install google-genai
```

```bash
npm install @google/genai
```

</MultiLanguage>

<LLMsSDKsCallout />

</Step>

<Step title="Initialize PostHog and Google Gen AI client" badge="required">

In the spot where you initialize the Google Gen AI SDK, import PostHog and our Google Gen AI wrapper, initialize PostHog with your project API key and host from [your project settings](https://app.posthog.com/settings/project), and pass it to our wrapper.

<MultiLanguage>

```python
from posthog.ai.gemini import Client
from posthog import Posthog

posthog = Posthog(
    "<ph_project_api_key>",
    host="<ph_client_api_host>"
)

client = Client(
    api_key="...", # Replace with your Gemini API key
    posthog_client=posthog # This is an optional parameter. If it is not provided, a default client will be used.
)
``` 

```typescript
import { GoogleGenAI } from '@posthog/ai'
import { PostHog } from 'posthog-node'

const phClient = new PostHog(
  '<ph_project_api_key>',
  { host: '<ph_client_api_host>' }
)

const client = new GoogleGenAI({
  apiKey: '...', // Replace with your Gemini API key
  posthog: phClient
})
```

</MultiLanguage>

</Step>

<Step title="Call Google Gen AI LLMs" badge="required">

Now, when you use the Google Gen AI SDK, it automatically captures many properties into PostHog including `$ai_input`, `$ai_input_tokens`, `$ai_cache_read_input_tokens`, `$ai_cache_creation_input_tokens`, `$ai_latency`, `$ai_tools`, `$ai_model`, `$ai_model_parameters`, `$ai_output_choices`, and `$ai_output_tokens`.

You can also capture or modify additional properties with the distinct ID, trace ID, properties, groups, and privacy mode parameters.

<MultiLanguage>

```python
response = client.models.generate_content(
    model="gemini-2.5-flash",
    contents=["Tell me a fun fact about hedgehogs"],
    posthog_distinct_id="user_123", # optional
    posthog_trace_id="trace_123", # optional
    posthog_properties={"conversation_id": "abc123", "paid": True}, # optional
    posthog_groups={"company": "company_id_in_your_db"},  # optional 
    posthog_privacy_mode=False # optional
)

print(response.text)
```

```typescript
const response = await client.models.generateContent({
  model: "gemini-2.5-flash",
  contents: ["Tell me a fun fact about hedgehogs"],
  posthogDistinctId: "user_123", // optional
  posthogTraceId: "trace_123", // optional
  posthogProperties: { conversationId: "abc123", paid: true }, // optional
  posthogGroups: { company: "company_id_in_your_db" }, // optional
  posthogPrivacyMode: false // optional
})

console.log(response.text)
phClient.shutdown() 
```

</MultiLanguage>

**Notes:** 
- If you want to capture LLM events anonymously, **don't** pass a distinct ID to the request. See our docs on [anonymous vs identified events](/docs/data/anonymous-vs-identified-events) to learn more. 

</Step>

<VerifyLLMEventsStep />


</Steps>