Start by installing the Anthropic Python SDK:

```bash
pip install anthropic
```

In the spot where you initialize the Anthropic SDK, import PostHog and our Anthropic wrapper, initialize PostHog with your project API key and host (from [your project settings](https://us.posthog.com/settings/project)), and pass it to our Anthropic wrapper.

```python
from posthog.ai.anthropic import Anthropic
import posthog

posthog.project_api_key = "<ph_project_api_key>"
posthog.host = "<ph_client_api_host>"

client = Anthropic(
    api_key="sk-ant-api...",  # Replace with your Anthropic API key
    posthog_client=posthog
)
``` 

> **Note:** This also works with the `AsyncAnthropic` client as well as `AnthropicBedrock`, `AnthropicVertex`, and the async versions of those.

Now, when you use the Anthropic SDK, it automatically captures many properties into PostHog including `$ai_input`, `$ai_input_tokens`, `$ai_latency`, `$ai_model`, `$ai_model_parameters`, `$ai_output_choices`, and `$ai_output_tokens`.

You can also capture additional properties like `posthog_distinct_id`, `posthog_trace_id`, `posthog_properties`, `posthog_groups`, and `posthog_privacy_mode`.

```python
response = client.messages.create(
    model="claude-3-opus-20240229",
    messages=[
        {
            "role": "user",
            "content": "Tell me a fun fact about hedgehogs"
        }
    ],
    posthog_distinct_id="user_123", # optional
    posthog_trace_id="trace_123", # optional
    posthog_properties={"conversation_id": "abc123", "paid": True}, # optional
    posthog_groups={"company": "company_id_in_your_db"},  # optional 
    posthog_privacy_mode=False # optional
)

print(response.content[0].text)
```

> **Notes:** 
> - This also works when message streams are used (e.g. `stream=True` or `client.messages.stream(...)`).
> - If you want to capture LLM events anonymously, **don't** pass a distinct ID to the request. See our docs on [anonymous vs identified events](/docs/data/anonymous-vs-identified-events) to learn more. 