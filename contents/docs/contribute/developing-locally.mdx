---
title: Developing locally
sidebar: Docs
showTitle: true
---

<blockquote class="warning-note">
    ⚠️ Do not use <code>release-*</code> patterns in your branches unless pushing a release as these branches have
    special handling related to releases.
</blockquote>

## What does it take?

To run PostHog, you must run the following services:

- PostHog's Django backend
- PostHog's Celery worker
- PostHog's Node.js plugin server
- PostHog's Node.js frontend
- PostgreSQL
- Redis
- ClickHouse
- Kafka
- Zookeeper

The guide below explains how to get them all running.

The supported way of running PostHog locally is:
- all services (Postgres, Redis, ClickHouse, Kafka, Zookeeper) run via Docker
- PostHog itself runs on the host (your system)

> It is also technically possible to run PostHog in Docker, but syncing changes is then much slower, and for development you need PostHog dependencies installed on the host anyway (such as formatting or typechecking tools).

The instructions below assume you're running macOS. For Linux, adjust the steps as needed (e.g. use your distro's package manager instead of `brew`).

In case some steps here have fallen out of date, please tell us about it by [submitting a patch](https://github.com/PostHog/posthog.com/tree/master/contents/docs/contribute/developing-locally.mdx).

## macOS prerequisites

1. Install Xcode developer tools if you haven't already: `xcode-select --install`.

2. Install the package manager Homebrew by following the [instructions here](https://brew.sh/).

<blockquote class="warning-note">
    Note: After installation, make sure to follow the instructions printed in your terminal to add Homebrew to your `$PATH`. Otherwise the command line will not know about packages installed with `brew`. Same for `nvm` and `pyenv` below.
</blockquote>

3. Install [Docker Desktop](https://www.docker.com/products/docker-desktop) and give Docker **at least 4 GB of RAM** (or 6 GB if you can afford it) and 4 CPU cores.

4. Append line `127.0.0.1 kafka clickhouse` to `/etc/hosts`. You can do it in one line with:

```bash
sudo echo '127.0.0.1 kafka clickhouse' | sudo tee -a /etc/hosts
```

Somehow ClickHouse and Kafka won't be able to talk to each other without these mapped hosts.

5. Clone the [PostHog repository](https://github.com/posthog/posthog). All future commands assume you're inside the `posthog/` folder.

```bash
git clone https://github.com/PostHog/posthog && cd posthog
```

## Get things up and running

### Step 1: backend services

In this step we will install Postgres, Redis, ClickHouse, Kafka and Zookeeper via Docker.

First, run the services via Docker:

```bash
# ARM (arm64) systems (e.g. Apple Silicon)
docker-compose -f ee/docker-compose.ch.arm64.yml pull zookeeper kafka clickhouse db redis
docker-compose -f ee/docker-compose.ch.arm64.yml up zookeeper kafka clickhouse db redis

# x86 (amd64) systems
docker-compose -f ee/docker-compose.ch.yml pull zookeeper kafka clickhouse db redis
docker-compose -f ee/docker-compose.ch.yml up zookeeper kafka clickhouse db redis
```

> **Friendly tip 1:** If you see `Error while fetching server API version: 500 Server Error for http+docker://localhost/version:`, likely Docker Engine isn't running.

> **Friendly tip 2:** If you see "Exit Code 137" anywhere, it means that the container has run out of memory. In this case you need to allocate more RAM in Docker Desktop settings.

> **Friendly tip 3:** You _might_ need `sudo` – see [Docker docs on managing Docker as a non-root user](https://docs.docker.com/engine/install/linux-postinstall).


Second, verify via `docker ps` and `docker logs` (or via the Docker Desktop dashboard) that all these services are up and running. They should display something like this in their logs:

```
# docker ps
CONTAINER ID   IMAGE                                  COMMAND                  CREATED        STATUS        PORTS                                                                                            NAMES
b0f72510b818   posthog/clickhouse:v21.9.2.17-stable   "/entrypoint.sh"         26 hours ago   Up 21 hours   0.0.0.0:8123->8123/tcp, 0.0.0.0:9000->9000/tcp, 0.0.0.0:9009->9009/tcp, 0.0.0.0:9440->9440/tcp   ee_clickhouse_1
12d146b93d69   wurstmeister/kafka                     "start-kafka.sh"         26 hours ago   Up 21 hours   0.0.0.0:9092->9092/tcp                                                                           ee_kafka_1
432afd46fc93   postgres:12-alpine                     "docker-entrypoint.s…"   26 hours ago   Up 21 hours   0.0.0.0:5432->5432/tcp                                                                           ee_db_1
cdbf065ffa3f   zookeeper                              "/docker-entrypoint.…"   26 hours ago   Up 21 hours   2181/tcp, 2888/tcp, 3888/tcp, 8080/tcp                                                           ee_zookeeper_1
ff77dcf7facd   redis:alpine                           "docker-entrypoint.s…"   26 hours ago   Up 21 hours   0.0.0.0:6379->6379/tcp                                                                           ee_redis_1

# docker logs ee_db_1 -n 1
2021-12-06 13:47:08.325 UTC [1] LOG:  database system is ready to accept connections

# docker logs ee_redis_1 -n 1
1:M 06 Dec 2021 13:47:08.435 * Ready to accept connections

# docker logs ee_clickhouse_1 -n 1
Saved preprocessed configuration to '/var/lib/clickhouse/preprocessed_configs/users.xml'.

# docker logs ee_kafka_1
[2021-12-06 13:47:23,814] INFO [KafkaServer id=1001] started (kafka.server.KafkaServer)

# docker logs ee_zookeeper_1
# Because ClickHouse and Kafka connect to Zookeeper, there will be a lot of noise here. That's good.
```

> **Friendly tip:** Kafka is currently the only x86 container used, and might segfault randomly when running on Apple Silicon. Restart it when that happens.

Finally, install Postgres locally. Even planning to run Postgres inside Docker, we need a local copy of Postgres (version 11+) for its CLI tools and development libraries/headers. These are required by `pip` to install `psycopg2`.

On macOS you can just run:
```bash
brew install postgresql
```
This installs both the Postgres server and its tools. DO NOT start the server after running this.

On Linux you often have separate packages: `postgres` for the tools, `postgres-server` for the server, and `libpostgres-dev` for the `psycopg2` dependencies. Consult your distro's list for an up-to-date list of pacakages.

### Step 2: Node.js frontend

1. Install nvm: https://github.com/nvm-sh/nvm. If using fish, you may instead prefer https://github.com/jorgebucaran/nvm.fish.

2. Install the latest Node.js 14 (the version used by PostHog in production) with `nvm install 14`. You can start using it in the current shell with `nvm use 14`.

3. Install yarn with `npm install -g yarn@1`

4. Install npm packages by running `yarn`

5. Run `yarn start`, which runs in parallel 1) our [esbuild](https://esbuild.github.io/)-powered dev server, 2) [kea-typegen](https://github.com/keajs/kea-typegen), which generates `logicType.ts` files for each `logic.ts` in the codebase.

6. The first time you run typegen, it may get stuck in a loop. If so, cancel the process (`ctrl+c`), discard all changes in the working directory (`git reset --hard`), and run `yarn start` again. You may need to discard all changes once more when the second round of type generation completes.

### Step 3: Node.js plugin server

1. Assuming NodeJS is installed, run `yarn --cwd plugin-server` to install all required packages.

### Step 5: Python backend

1. Install pyenv by following the [instructions here](https://github.com/pyenv/pyenv).

2. Install the latest path release of Python 3.9 with `pyenv install 3.9` (and then selecting the precise version from the list presented). For example:

```
pyenv install 3.9 # gives a list of versions to install
pyenv install 3.9.9
pyenv global 3.9.9
```

3. Create the virtual environment in current directory called 'env':

```bash
python3 -m venv env
```

4. Activate the virtual environment:

```bash
# for bash/zsh/etc
source env/bin/activate

# if you're using the fish shell
source env/bin/activate.fish
```

5. Install requirements with pip

If you're on Apple Silicon, the first time your run `pip install` you must pass it custom openssl headers:

```bash
brew install openssl
CFLAGS="-I /opt/homebrew/opt/openssl/include" LDFLAGS="-L /opt/homebrew/opt/openssl/lib" GRPC_PYTHON_BUILD_SYSTEM_OPENSSL=1 GRPC_PYTHON_BUILD_SYSTEM_ZLIB=1 pip install -r requirements.txt
```

These will be used when installing `grpcio` and `psycopg2`. After doing this once, and assuming nothing changed with these two packages, next time simply run:

```bash
pip install -r requirements.txt
```

6. SAML support.

If you want to fully test all our features, you'll need to install a few dependencies for SAML to run properly. If you're on macOS, run the command below, otherwise check out the official [xmlsec repo](https://github.com/mehcode/python-xmlsec) for more details.

```
brew install libxml2 libxmlsec1 pkg-config
pip install python3-saml==1.12.0
```

7. Install dev requirements:

```bash
pip install -r requirements-dev.txt
```

### Step 5: Run database migrations

```bash
export DEBUG=1
export PRIMARY_DB=clickhouse
export SKIP_SERVICE_VERSION_REQUIREMENTS=1
export DATABASE_URL=postgres://posthog:posthog@localhost:5432/posthog

python manage.py migrate
python manage.py migrate_clickhouse
```

> **Friendly tip:** The error `fe_sendauth: no password supplied` connecting to Postgres happens when the database is set up with a password and the user:pass isn't specified in `DATABASE_URL`. Try `export DATABASE_URL=postgres://posthog:posthog@localhost:5432/posthog`.

> **Another friendly tip:** You may run into `psycopg2` errors while migrating on a Apple Silicon machine. Try out the steps in this [comment](https://github.com/psycopg/psycopg2/issues/1216#issuecomment-820556849) to resolve this.

### Step 6: Start PostHog

Now start all of PostHog (backend, worker, plugin server, and frontend – simultaneously) with:

```bash
export KAFKA_HOSTS=kafka:9092
./bin/start
```

Open [http://localhost:8000](http://localhost:8000) to see the app.

> **Note:** The first time you run this command you might get an error that says "layout.html is not defined". Make sure you wait until the frontend is finished compiling and try again.

To see some data on the frontend, you should go to the `http://localhost:8000/demo` and play around with it. This will give you a Hogflix test project containing some data data in the app.

## Testing

For a PostHog PR to be merged, all tests must be green.

Run backend tests locally simply with:
```bash
pytest
```
You can narrow down the run to only files under matching paths:
```bash
pytest posthog/test/test_entity_model.py
```
Or to only test cases with matching function names:
```bash
pytest posthog/test/test_entity_model.py -k test_inclusion
```
To see debug logs (such as ClickHouse queries), add argument `--log-cli-level=DEBUG`.

For Cypress end-to-end test, run `bin/e2e-test-runner`. This will temporarily install required dependencies inside the project, spin up a test instance of PostHog, and show you the Cypress interface, from which you'll manually choose tests to run.

#### Debugging the backend in PyCharm

With [PyCharm's](https://posthog.com/handbook/engineering/beginners-guide/developer-workflow#alternative-pycharm) built in support for Django, it's fairly easy to setup debugging in the backend. This is especially useful when you want to trace and debug a network request made from the client all the way back to the server. You can set breakpoints and step through code to see exactly what the backend is doing with your request.

1. Setup Django configuration as per JetBrain's [docs](https://blog.jetbrains.com/pycharm/2017/08/develop-django-under-the-debugger/).
2. Click Edit Configuration to edit the Django Server configuration you just created.
3. Point PyCharm to the project root (`posthog/`) and settings (`posthog/posthog/settings.py`) file.
4. Add these environment variables

```
DEBUG=1;
KAFKA_HOSTS=kafka:9092;
DATABASE_URL=postgres://posthog:posthog@localhost:5432/posthog
```

## Testing ingestion and feature flags

> **Note:** When developing locally with environment variable `DEBUG=1` (which enables a setting called `SELF_CAPTURE`), all analytics inside your local PostHog instance is based on that instance itself – more specifically, the currently selected project. This means that your activity is immediately reflected in the current project, which is potentially useful for testing features – for example, which feature flags are currently enabled for your development instance is decided by the project you have open at the very same time.

Run `python manage.py sync_feature_flags` to create all used flags locally.

Add feature flags to your [local instance](http://localhost:8000/feature_flags/new) to use them while developing locally. For example, let's say you want to test the using the `my-feature-flag` flag locally - you would create a new flag with the name `my-feature-flag` and release that flag to the user account used for testing. Learn more about using feature flags in the [Feature Flags user guide](//posthog.com/docs/user-guides/feature-flags).
