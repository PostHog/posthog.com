---
title: Deploying to Google Cloud Platform
sidebarTitle: Google Cloud Platform
sidebar: Docs
showTitle: true
tags:
  - gcp
---

import InstallingSnippet from './snippets/installing'
import UpgradingSnippet from './snippets/upgrading'
import UninstallingSnippet from './snippets/uninstalling'

First, we need to set up a Kubernetes Cluster. See [Google Cloud Kubernetes Engine (GKE)](https://cloud.google.com/kubernetes-engine/).

Here's the minimal required `values.yaml` that we'll be using later. You can find an overview of the parameters that can be configured during installation under [configuration](/docs/self-host/deploy/configuration).
```yaml
cloud: "gcp"
ingress:
  hostname: <your-hostname>
  nginx:
    enabled: false
certManager:
  enabled: false
```

### Installing the chart

<InstallingSnippet />

## Set up a static IP

1. Open the Google Cloud Console
1. Go to VPC Networks > [External IP addresses](https://console.cloud.google.com/networking/addresses/list)
1. Add a new global static IP with the name `posthog`

## Setting up DNS

Create a record from your desired hostname to the external IP.


## Troubleshooting
### I cannot connect to my PostHog instance after creation

If DNS has been updated properly, check whether the SSL certificate was created successfully.

This can be done via the following command:

```console
gcloud beta --project yourproject compute ssl-certificates list
```

If running the command shows the SSL cert as `PROVISIONING`, that means that the certificate is still being created. [Read more on how to troubleshoot Google SSL certificates here](https://cloud.google.com/load-balancing/docs/ssl-certificates/troubleshooting).

As a troubleshooting tool, you can allow HTTP access by setting `ingress.gcp.forceHttps` and `web.secureCookies` both to false, but we recommend always accessing PostHog via https.

## Upgrading the chart
<UpgradingSnippet />

## Uninstalling the chart
<UninstallingSnippet />

## Clickhouse Configuration

By default clickhouse is provisioned with standard gcp persistent disk. If you want to specify your own persistent volume claim or switch to a different type of disk
you can specify the volume claim within `values.yaml`.

### To manually provision a disk

Using the gcloud cli tool for provisioning a disk:

```
gcloud compute disks create pvc-clickhouse --type=pd-ssd --size=2048GB --zone=us-central1-c
```

### Create the claim

In order to provide the disk to the clickhouse deployment you must first create a persistent volume and claim within the posthog namespace.

```
# This creates a volume claim using the same name specified within the clickhouse values file
apiVersion: v1
kind: PersistentVolume
metadata:
  name: clickhouse-volume
spec:
  persistentVolumeReclaimPolicy: Retain
  storageClassName: ""
  capacity:
    storage: 2048Gi
  accessModes:
    - ReadWriteOnce
  gcePersistentDisk:
    pdName: pvc-clickhouse
    fsType: ext4
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: clickhouse-pvc
spec:
  # It's necessary to specify "" as the storageClassName
  # so that the default storage class won't be used, see
  # https://kubernetes.io/docs/concepts/storage/persistent-volumes/#class-1
  storageClassName: ""
  volumeName: clickhouse-volume
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 2048Gi
```

### Provide the claim to the helm chart

```
clickhouse:
  # -- Optional: Used to manually specify a persistent volume claim. When specified the cloud specific storage class will not be provisioned
  persistentVolumeClaim: "clickhouse-pvc"
```