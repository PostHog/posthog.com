---
title: S3 Destination for Batch Exports
sidebar: Docs
showTitle: true
availability:
    free: full
    selfServe: full
    enterprise: full
---

With PostHog Batch Exports, data can be exported to an S3 bucket.

## Creating the Batch Export

1. Navigate to the Batch Exports UI (Quick links if you use [PostHog Cloud US](https://app.posthog.com/project/exports) or [PostHog Cloud EU](https://eu.posthog.com/project/exports)).
2. Select S3 as the Batch Export type.
3. Fill in the necessary [configuration details](#s3-configuration).
4. Click on Create Export.
5. Done! The Batch Export will schedule its first run on the start of the next period.

## S3 configuration

Configuring a Batch Export targeting S3 requires the following S3-specific configuration values:
* Bucket name: The name of the S3 bucket where the data is to be exported.
* Region: The AWS region where the bucket is located.
* Key prefix: A key prefix to use for each S3 object created. This key can include [template variables](#s3-key-prefix-template-variables)
* AWS Access Key ID: An AWS access key ID with access to the S3 bucket.
* AWS Secret Access Key: An AWS secret access key with access to the S3 bucket.

### S3 key prefix template variables

The key prefix provided for data exporting can include template variables which are formatted at runtime. All template variables are defined between curly brackets (for example `{day}`). This allows you partition files in your S3 bucket, for example, by date.

Template variables include:
* Date and time variables:
  * `year`.
  * `month`.
  * `day`.
  * `hour`.
  * `minute`.
  * `second`.
* Name of the table exported:
  * `table_name`.
* Batch export data bounds:
  * `data_interval_start`.
  * `data_interval_end`.

So, as an example, setting `{year}-{month}-{day}_{table_name}/` as a key prefix, will produce files prefixed with keys like `2023-07-28_events/`.
