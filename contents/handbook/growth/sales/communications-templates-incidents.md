---
title: Communcation templates for incidents
sidebar: Handbook
showTitle: true
---

When things go wrong, our priority is simple: **keep customers informed, quickly and clearly.**

This section covers how we communicate during service disruptions, from small hiccups to major outages. We aim to be **transparent, human, and proactive** â€” sharing what we know (and what we don't) in plain English.

> For the engineering incident response process, see [Handling an incident](/handbook/engineering/operations/incidents).

PostHog customers rely on us to power their products, so we provide honest, timely updates through the right channels â€” usually Slack or email, and occasionally SMS for highâ€‘touch accounts.

## **Core principles**

### **1\. Transparency \> Perfection**

Share what we know, when we know it, clearly and without â€œstatus-speak.â€

### **2\. Human-centric**

Messages come from people, not â€œThe PostHog Team.â€ Show empathy and ownership (â€œI know this might interrupt your work; hereâ€™s what weâ€™re doing.â€)

### **3\. Consistency**

Use a consistent structure and timing so customers know what to expect.

### **4\. Proactive by default**

Reach out before customers ask, even if itâ€™s just to say, â€œWeâ€™re aware and investigating.â€

## **âš™ï¸ Severity levels**

| Level | Description | Examples | Channels | Cadence |
| ----- | ----- | ----- | ----- | ----- |
| **SEV 1 â€“ Critical** | Major outage or data loss; widespread impact. | API unavailable, ingestion halted, login failures. | Slack â†’ Email â†’ (DM or SMS if needed) | Every 30â€“60 min; postmortem within 48h |
| **SEV 2 â€“ Major** | Partial degradation or downtime; workaround available. | Replay or query delays \>30 min, flag evaluation slow. | Slack or Email | Every 1â€“2 hrs |
| **SEV 3 â€“ Minor** | Limited impact or slow recovery. | Billing sync delays, isolated org issues. | Slack | Start and close |
| **SEV 4 â€“ Informational / Planned** | Maintenance or recovered incidents. | DB upgrade, scaling events. | Email or Slack broadcast | Before \+ after window |

## **Templates**

### **Critical**

**Subject:** ğŸ›‘ PostHog Outage â€“ Weâ€™re investigating

Hey \[Name/Team\],

Weâ€™re investigating a major outage affecting \[feature\]. You may see \[symptom\]. Engineers are on it â€” updates every 30 minutes until resolved.

We know this may disrupt your work â€” thanks for your patience while we get things back online.

â€” \[Your Name\], PostHog

**Follow-Up (Resolution):** Good news â€” the issue is resolved. Root cause: \[summary\].
Duration: \[startâ€“end\].
Impact: \[brief effect\].

Weâ€™re monitoring and will share a full write-up within 48 hours.

### **Major**

**Subject:** âš ï¸ Performance issues in \[Feature\]

Hey \[Name\],

Weâ€™re seeing performance issues in \[component\]. You might notice \[impact\]. Weâ€™re mitigating and will update within the hour.

Thanks for your patience\!
â€” \[Your Name\], PostHog

---

### **Minor**

**Subject:** ğŸŸ¡ Slower performance in \\\[area\\\]

FYI â€” This shouldnâ€™t block you, but weâ€™re monitoring closely. Iâ€™ll update once itâ€™s stable.

---

### **Planned maintenance**

**Subject:** ğŸ›  Maintenance â€“ \[Service/Region\]

Heads up â€” maintenance on \[system\] from \[time window\]. No downtime expected, but queries or replays may be briefly delayed. Weâ€™ll confirm once complete.

---

## **Tone and voice**

| Principle | Example | Avoid |
| :---- | :---- | :---- |
| **Direct** | â€œEvent ingestion is paused.â€ | â€œWe are experiencing an issue affecting a subset of users.â€ |
| **Empathetic** | â€œI know this blocks work; itâ€™s our top priority.â€ | â€œWe apologize for the inconvenience.â€ |
| **Plain English** | â€œDashboards might not update.â€ | â€œYou may experience degraded query latency.â€ |
| **Ownership** | â€œWe identified a config issue on our side.â€ | â€œA third-party dependency caused an issue.â€ |

---

## **Coordination within GTM**

**Engineering manages detection and resolution** (see [engineering incident handbook](/handbook/engineering/operations/incidents)). GTM ensures clear, consistent customer updates, without duplication or coverage gaps.

### **Goals**

* Keep a single source of truth for comms, managed by the CMOC.
* Maintain global coverage so customers always hear from us.
* Enable fast, clear handoffs between teams.

### **Roles & responsibilities**

| Role | Responsibility |
| :---- | :---- |
| **Communications Manager On-Call (CMOC)** | Activated for any incident requiring GTM notification. Drafts all comms using handbook templates. Coordinates with engineering for context and keeps a central log of whoâ€™s been notified. Manages regional handoffs if incidents span time zones or owners are offline. |
| **AM/AE/CSM** | Sends comms to their accounts using CMOC drafts. If offline (PTO, off-hours, or time zone), CMOC assigns a regional backup. |
| **Regional Backup (Americas / EMEA / APAC)** | Covers accounts when owners are offline. Takes handoff from CMOC, sends comms, and ensures follow-up continuity. |
| **Engineering Incident Lead** | Owns technical response and provides updates to CMOC for accurate messaging. |

### **Workflow**

1. **Incident declared** (Engineering).
2. **CMOC activated**, notified of impact.
3. **CMOC drafts the initial message**, shares with the Account Owner.
4. **AM/AE/CSM sends to accounts**; backup sends if primary is offline.
5. **Updates** drafted by CMOC (30â€“60 min for SEV1, 1â€“2 hrs for SEV2).
6. **Regional handoffs** coordinated by CMOC.
7. **Resolution**: CMOC drafts closure; AM/AE/CSM (or backup) sends.
8. **Post-incident**: CMOC archives thread; GTM logs feedback and follow-ups.
9. **Postmortem**: Engineering writes technical summary; GTM adds comms learnings.

## **Example Slack workflow (Critical)**

1. **Incident created**: \#inc-2025-11-05-posthog-feature-flags-error.
2. **SRE posts summary; CMOC coordinates comms.**
3. **CMOC drafts message** and shares with the **Account Owner** (the person responsible for the affected accounts).
4. **Account Owner sends the message** to their customers. Example outbound: â€œWeâ€™re investigating an outage affecting event ingestion. Updates every 30 minutes.â€
5. **During:** â€œRoot cause identified (Redis queue saturation). Fix in progress.â€
6. **Resolution:** â€œResolved at 11:42 UTC. Write-up soon.â€
