---
title: How to set up MCP analytics and error tracking
date: 2025-10-14
author:
  - arda-eren
tags:
  - MCP
  - product analytics
  - feature flags
---

MCP servers give LLMs powerful capabilities, but without analytics and error tracking you're flying blind with no visibility into usage or performance. Which tools get called? How often? Where are the bottlenecks? What's failing?

This tutorial will show you how to add product analytics and error tracking to any MCP server using a simple wrapper pattern. You'll automatically track every tool execution without touching your business logic. 

By the end, your MCP server will be able to:

- Track execution time for every tool call
- Capture errors with context
- Record custom metrics
- Sanitize sensitive data

This integration pattern works for any MCP server and is vendor-agnostic. We'll use PostHog for this tutorial but you can use any developer tool you prefer.

The full source code is available in this [GitHub repository](https://github.com/arda-e/mcp-posthog-analytics).

## Prerequisites

- Node.js 18+ 
- PostHog account (free tier)
- Claude Desktop or another MCP client to test your MCP server
- Basic TypeScript knowledge
- Code editor (e.g., VS Code, Cursor)

## A high-level overview of MCP analytics


## The wrapper pattern for MCP tools

MCP servers have an architecture that makes the wrapper pattern a natural fit for extended functionality like analytics and error tracking. Why? MCP's functional design means wrapper patterns work seamlessly, unlike other web frameworks with middleware pipelines or class-based systems with decorators.

Here's what the boilerplate code looks like for MCP tool registration: 

```typescript
// This is how MCP tools are registered, already functional style
server.tool(
  "toolName",
  { /* schema */ },
  { /* metadata */ },
  async (args) => { /* handler function */ }
);
```

Since MCP tools are mostly just async functions passed to `server.tool()`, wrapping the handler function is a clean and lightweight way of adding or extending functionality – in this case, analytics.

This is the key integration pattern we'll use to build MCP analytics.

## 1. Define the MCP analytics provider 

The first step is define an interface for an analytics provider. It defines a standard set of methods for sending analytics data from your MCP server. 

We'll give it three core abilities:

1. Track tool calls 
2. Capture errors 
3. Close the analytics client

```typescript file="src/analytics.ts"
export interface AnalyticsProvider {
  /**
   * Track a successful tool execution with timing information
   * @param toolName - Name of the tool that was executed
   * @param result - Execution results including duration and success status
   */
  trackTool(toolName: string, result: any): Promise<void>;
  
  /**
   * Track an error that occurred during tool execution
   * @param error - The error object that was thrown
   * @param context - Additional context about the error (tool name, duration, etc.)
   */
  trackError(error: Error, context: any): Promise<void>;
  
  /**
   * Gracefully shut down the analytics client and flush pending events
   */
  close(): Promise<void>;
}
```

This approach makes your code testable and flexible. Think of it as a generic adapter for analytics calls. 

Want to use a different analytics provider? Write a new implementation. Need to debug locally? Create a file-based logger. Running tests? Use a no-emit version that tracks calls without sending data.

## 2. Create the withAnalytics wrapper

The next step is create a wrapper that intercepts every tool call. The wrapper function is responsible for invoking the analytics provider methods we defined in the previous step.

```typescript file="src/analytics.ts"
// src/analytics.ts
export async function withAnalytics<T>(
  analytics: AnalyticsProvider | undefined,
  toolName: string,
  handler: () => Promise<T>
): Promise<T> {
  const start = Date.now();
  
  try {
    const result = await handler();
    const duration_ms = Date.now() - start;
    
    // Track successful execution
    await analytics?.trackTool(toolName, { 
      duration_ms, 
      success: true 
    });
    
    return result;
    
  } catch (error) {
    const duration_ms = Date.now() - start;
    
    // Track the error with context
    await analytics?.trackError(error as Error, {
      tool_name: toolName,
      duration_ms
    });
    
    throw error; // Re-throw so MCP handles it normally
  }
}
```

The `withAnalytics()` wrapper function:

- Times every tool call execution 
- Tracks success/failure 
- Preserves normal error handling
- Works without an analytics provider

## 3. Create MCP tools

Now that our analytics wrapper is ready, let's create our MCP tools. For this tutorial, we'll hardcode simple datasets and results for the tools to fetch. 

```typescript file="src/tools.ts"
// src/tools.ts
export async function getInventory() {
  return [
    { id: '1', name: 'Widget', stock: 42 },
    { id: '2', name: 'Gadget', stock: 17 }
  ];
}

export async function checkStock(productId: string) {
  const stock = { '1': 42, '2': 17 }[productId];
  if (!stock) {
    throw new Error(`Product ${productId} not found`);
  }
  return { productId, stock };
}

export async function analyzeData(data: string) {
  // Simulate expensive operation
  await new Promise(resolve => setTimeout(resolve, 1000));
  return { result: `Analysis complete`, confidence: 0.92 };
}
```

Notice that these tools contain *only* business logic, with zero analytics dependencies. Keeping your tool definitions decoupled from other external logic makes them easier to test, maintain, and reuse across different contexts.
 
## 4. Register tools with analytics

Now it's time to register your tools with the MCP server, wrapping each handler function with the `withAnalytics()` wrapper.

```typescript file="src/server.ts"
// src/server.ts
import { McpServer } from "@modelcontextprotocol/sdk/server/mcp.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import { z } from "zod";
import * as tools from "./tools.js";
import { withAnalytics } from "./analytics.js";

export async function createServer(analytics?: AnalyticsProvider) {
  const server = new McpServer({
    name: "analytics-demo",
    version: "1.0.0"
  });

  // Register each tool wrapped with analytics
  server.tool(
    "getInventory",
    {},
    { title: "Get product inventory" },
    async () => withAnalytics(
      analytics, 
      "getInventory", 
      tools.getInventory
    )
  );

  server.tool(
    "checkStock",
    { productId: z.string() },
    { title: "Check stock for a product" },
    async (args) => withAnalytics(
      analytics,
      "checkStock",
      () => tools.checkStock(args.productId)
    )
  );

  server.tool(
    "analyzeData",
    { data: z.string() },
    { title: "Analyze data (slow)" },
    async (args) => withAnalytics(
      analytics,
      "analyzeData",
      () => tools.analyzeData(args.data)
    )
  );

  const transport = new StdioServerTransport();
  await server.connect(transport);
  
  console.error("[MCP] Server running");
  return server;
}
```

If you want capture additional custom properties, you can adapt the wrapper pattern and call the `trackTool()` method with the additional properties.

```typescript file="src/server.ts"
// In src/server.ts
server.tool(
  "getInventory",
  {},
  { title: "Get product inventory" },
  async () => withAnalytics(
    analytics,
    "getInventory",
    async () => {
      const result = await tools.getInventory();
      
      // Track additional custom metrics as a SEPARATE event
      await analytics?.trackTool("inventory_metrics", {
        duration_ms: 0,
        success: true,
        items_returned: result.length,
        cache_hit: false
      });
      
      return result;
    }
  )
);
```

## 5. Implement PostHog tracking

Now let's send those analytics somewhere useful. The next integration step is to initialize a PostHog SDK client that implements the `AnalyticsProvider` interface. 

```typescript file="src/posthog.ts"
// src/posthog.ts
import { PostHog } from "posthog-node";
import { AnalyticsProvider } from "./analytics.js";

export class PostHogAnalyticsProvider implements AnalyticsProvider {
  private client: PostHog;
  private sessionId: string;

  constructor(apiKey: string, host?: string) {
    this.client = new PostHog(apiKey, { host });
    this.sessionId = `mcp_${Date.now()}_${process.pid}`;
  }
  
  async trackTool(toolName: string, result: any): Promise<void> {
    this.client.capture({
      distinctId: this.sessionId,
      event: "mcp_tool_executed",
      properties: { tool_name: toolName, ...result }
    });
    
    console.error(
      `[Analytics] ${toolName}: ${result.success ? "✓" : "✗"} (${result.duration_ms}ms)`
    );
  }
  
  async trackError(error: Error, context: any): Promise<void> {
    this.client?.captureException(error, "", {
        sessionId: this.sessionId,
        duration_ms: context.duration_ms,
        args: this.anonymizeData ? this.anonymize(context.args) : context.args,
    });
  }
  
  async close(): Promise<void> {
    await this.client.shutdown();
  }
}
```

The `PostHogAnalyticsProvider` class leverages the PostHog [Node.js SDK](/docs/libraries/node) to capture [custom events](/docs/product-analytics/capture-events) for product analytics and exceptions for built-in [error tracking](/docs/error-tracking).

## 6. Create the MCP server

The last implementation step is to create the MCP server with our `PostHogAnalyticsProvider` instance.

```typescript file="src/index.ts"
// src/index.ts
import "dotenv/config";
import { createServer } from "./server.js";
import { PostHogAnalyticsProvider } from "./posthog.js";

async function main() {
  let analytics;
  
  if (process.env.POSTHOG_API_KEY) {
    analytics = new PostHogAnalyticsProvider(
      process.env.POSTHOG_API_KEY,
      process.env.POSTHOG_HOST
    );
  }

  const server = await createServer(analytics);

  process.on("SIGINT", async () => {
    await server.close();
    await analytics?.close();
    process.exit(0);
  });
}

main().catch(console.error);
```

## 7. Test with Claude Desktop

Now we can test our MCP server with Claude Desktop, or any compatible MCP client, to see MCP analytics in action.

Build the MCP server:

```bash
npm install && npm run build
```

Configure Claude Desktop to use the MCP server:

```json
// ~/Library/Application Support/Claude/claude_desktop_config.json
{
  "mcpServers": {
    "analytics-demo": {
      "command": "/path/to/node",
      "args": ["/path/to/project/build/index.js"],
      "env": {
        "POSTHOG_API_KEY": "<ph_project_api_key>",
        "POSTHOG_HOST": "<ph_client_api_host>" // e.g. https://us.i.posthog.com
      }
    }
  }
}
```

Try these prompts:

- "Show me the inventory" → Should successfully return the inventory.
- "Check stock for product 999" → Should throw an error.
- "Analyze this data: quarterly sales" → Simulates a slow operation.

<ProductVideo
  videoLight="https://res.cloudinary.com/dmukukwp6/video/upload/mcp_tool_call_compressed_bc097fc4ae.mp4"
  alt="MCP server tool calls with Claude Desktop"
  classes="rounded"
  autoPlay={true}
  loop={true}
/>

<Caption>
Our MCP server executing tool calls.
</Caption>

## 8. Create MCP analytics dashboards

Now that our MCP server is creating MCP analytics, we can create insights and dashboards in PostHog to visualize the data. We can create:

 - Performance dashboard
 - Reliability dashboard
 - Usage dashboard

Image tk...

<Caption>
P95 latency by tool (bar chart) to find slow operations
</Caption>

Image tk...

<Caption>
Success rate by tool (table) to identify problem areas
</Caption>

Image tk...

<Caption>
Tool popularity over time (line chart) to understand patterns
</Caption>

## Privacy and feature flags

If your tools handle sensitive information, you can sanitize it before tracking. PostHog offers both US and EU hosting options, so you can choose the region that meets your compliance requirements:

```typescript
async trackError(error: Error, context: any) {
  // Redact sensitive information in production
  const sanitized = {
    ...context,
    args: process.env.NODE_ENV === 'production' ? "[REDACTED]" : context.args,
    $exception_message: process.env.NODE_ENV === 'production' 
      ? error.name  // Only track error type, not the message
      : error.message
  };
  
  this.client.capture({
    distinctId: this.sessionId,
    event: "mcp_tool_error",
    properties: sanitized
  });
}
```
For GDPR compliance, use PostHog's EU cloud when initializing `host: 'https://eu.i.posthog.com'`. This ensures all your data stays within EU data centers.

You can also use PostHog's feature flags to roll out tool availability without redeploying:

```typescript
// src/posthog.ts - add this method to PostHogAnalyticsProvider
export class PostHogAnalyticsProvider implements AnalyticsProvider {
  // ... existing code ...
  
  async isFeatureEnabled(flagKey: string): Promise<boolean> {
    return await this.client.isFeatureEnabled(flagKey, this.sessionId) || false;
  }
}

// src/server.ts - conditionally register tools
export async function createServer(analytics?: PostHogAnalyticsProvider) {
  const server = new McpServer({
    name: "analytics-demo",
    version: "1.0.0"
  });

  // Always register stable tools
  server.tool("getInventory", {}, { title: "Get product inventory" },
    async () => withAnalytics(analytics, "getInventory", tools.getInventory)
  );

  // Only register experimental tools if feature flag is enabled
  if (analytics && await analytics.isFeatureEnabled('enable-experimental-tools')) {
    server.tool("analyzeData", { data: z.string() }, { title: "Analyze data" },
      async (args) => withAnalytics(analytics, "analyzeData", 
        () => tools.analyzeData(args.data)
      )
    );
  }

  // ... rest of setup
}
```

## Further reading

- Complete code on [GitHub](https://github.com/arda-e/mcp-posthog-analytics)
- [MCP: machine copy/paste](/blog/machine-copy-paste-mcp-intro)
- [What we've leanred about AI-powered features](/newsletter/building-ai-features)
- [Avoid these AI coding mistakes](/newsletter/ai-coding-mistakes)